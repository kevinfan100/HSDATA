#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HSData äºŒé€²åˆ¶æª”æ¡ˆè®€å–å™¨ - æ‰¹æ¬¡è™•ç†ç‰ˆæœ¬
æ”¯æ´æ•´å€‹è³‡æ–™å¤¾çš„æ‰¹æ¬¡è™•ç†å’Œè‡ªå‹•è·¯å¾‘çµæ§‹
"""

import struct
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
import os
import glob

class HSDataReader:
    """HSData äºŒé€²åˆ¶æª”æ¡ˆè®€å–å™¨ - ç²¾ç°¡ç‰ˆ"""
    
    # æª”æ¡ˆæ ¼å¼å¸¸æ•¸
    MAGIC_NUMBER = b'HSDATA\x00\x00'
    VERSION = 1
    HEADER_SIZE = 24
    RECORD_SIZE = 60

    def __init__(self, file_path: str | Path):
        self.file_path = Path(file_path)
        self.header: Optional[Dict] = None
        self.data_records: List[Dict] = []
        self._validate_file()

    def _validate_file(self):
        """é©—è­‰æª”æ¡ˆå­˜åœ¨æ€§å’ŒåŸºæœ¬æ ¼å¼"""
        if not self.file_path.exists():
            raise FileNotFoundError(f"æª”æ¡ˆä¸å­˜åœ¨: {self.file_path}")
        
        file_size = self.file_path.stat().st_size
        if file_size < self.HEADER_SIZE:
            raise ValueError(f"æª”æ¡ˆå¤ªå°: {file_size} bytes")

    def read_header(self) -> Dict:
        """è®€å–æª”æ¡ˆé ­éƒ¨è³‡è¨Š"""
        with open(self.file_path, 'rb') as f:
            header_data = f.read(self.HEADER_SIZE)
            
            if len(header_data) < self.HEADER_SIZE:
                raise ValueError("æª”æ¡ˆé ­éƒ¨æ•¸æ“šä¸å®Œæ•´")
            
            magic = header_data[0:8]
            version = struct.unpack('<I', header_data[8:12])[0]
            record_count = struct.unpack('<I', header_data[12:16])[0]
            timestamp = struct.unpack('<Q', header_data[16:24])[0]
            
            self.header = {
                'magic': magic.decode('ascii', errors='ignore').rstrip('\x00'),
                'version': version,
                'record_count': record_count,
                'timestamp': timestamp,
                'creation_time': datetime.fromtimestamp(timestamp),
                'file_size': self.file_path.stat().st_size
            }
            
            return self.header

    def validate_format(self) -> bool:
        """é©—è­‰æª”æ¡ˆæ ¼å¼"""
        if self.header is None:
            self.read_header()
        
        if not self.header['magic'].startswith('HSDATA'):
            print(f"âŒ ç„¡æ•ˆçš„ magic number: {self.header['magic']}")
            return False
        
        if self.header['version'] != self.VERSION:
            print(f"âŒ ä¸æ”¯æ´çš„ç‰ˆæœ¬è™Ÿ: {self.header['version']}")
            return False
        
        return True

    def read_data(self) -> List[Dict]:
        """è®€å–æ‰€æœ‰æ•¸æ“šè¨˜éŒ„"""
        records = []
        with open(self.file_path, 'rb') as f:
            f.seek(self.HEADER_SIZE)
            idx = 0
            
            while True:
                record_data = f.read(self.RECORD_SIZE)
                if len(record_data) < self.RECORD_SIZE:
                    break
                
                vm = struct.unpack('<6f', record_data[0:24])
                vd = struct.unpack('<6f', record_data[24:48])
                da = struct.unpack('<6H', record_data[48:60])
                
                records.append({
                    'index': idx, 
                    'vm': np.array(vm), 
                    'vd': np.array(vd), 
                    'da': np.array(da)
                })
                idx += 1
                
                # ç°¡å–®çš„é€²åº¦é¡¯ç¤º
                if idx % 50000 == 0:
                    print(f"å·²è®€å– {idx} ç­†è¨˜éŒ„...")
        
        self.data_records = records
        print(f"âœ“ æ•¸æ“šè®€å–å®Œæˆï¼Œå…± {len(records)} ç­†è¨˜éŒ„")
        return records
    
    def read_data_records(self) -> List[Dict]:
        """è®€å–æ‰€æœ‰æ•¸æ“šè¨˜éŒ„ (åˆ¥åæ–¹æ³•ï¼Œèˆ‡åŸå§‹ç¨‹å¼ç¢¼ç›¸å®¹)"""
        return self.read_data()

    def get_info(self) -> Dict:
        """å–å¾—æª”æ¡ˆåŸºæœ¬è³‡è¨Š"""
        if self.header is None:
            self.read_header()
        
        return {
            'file_path': str(self.file_path),
            'file_size_mb': round(self.header['file_size'] / (1024 * 1024), 2),
            'creation_time': self.header['creation_time'],
            'record_count': self.header['record_count'],
            'version': self.header['version'],
            'magic': self.header['magic']
        }

    def to_csv(self, output_path: Optional[str] = None) -> str:
        """è½‰æ›ç‚º CSV æª”æ¡ˆï¼Œè‡ªå‹•è™•ç†è·¯å¾‘"""
        if not self.data_records:
            self.read_data()
        
        # è‡ªå‹•ç”Ÿæˆè¼¸å‡ºè·¯å¾‘
        if output_path is None:
            output_path = self._get_auto_csv_path()
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        data = []
        for r in self.data_records:
            row = [r['index']] + r['vm'].tolist() + r['vd'].tolist() + r['da'].tolist()
            data.append(row)
        
        columns = ['index'] + [f'vm_{i}' for i in range(6)] + [f'vd_{i}' for i in range(6)] + [f'da_{i}' for i in range(6)]
        df = pd.DataFrame(data, columns=columns)
        
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"CSV å°å‡ºå®Œæˆ: {output_path}")
        return str(output_path)

    def _get_auto_csv_path(self) -> Path:
        """è‡ªå‹•ç”Ÿæˆ CSV è¼¸å‡ºè·¯å¾‘"""
        # å–å¾—å°ˆæ¡ˆæ ¹ç›®éŒ„
        project_root = self._find_project_root()
        
        # ç¢ºä¿æª”æ¡ˆè·¯å¾‘æ˜¯çµ•å°è·¯å¾‘
        file_path_abs = self.file_path.resolve()
        
        # å–å¾—ç›¸å°è·¯å¾‘ï¼ˆå¾ raw data é–‹å§‹ï¼‰
        try:
            raw_data_path = project_root / "01Data" / "01Raw_dat"
            relative_path = file_path_abs.relative_to(raw_data_path)
            
            # æ›¿æ›å‰¯æª”åä¸¦æ”¾åˆ° processed ç›®éŒ„
            csv_filename = relative_path.with_suffix('.csv')
            csv_path = project_root / "01Data" / "02Processed_csv" / csv_filename
            
            return csv_path
            
        except ValueError as e:
            print(f"ç„¡æ³•å–å¾—ç›¸å°è·¯å¾‘: {e}")
            # å¦‚æœç„¡æ³•å–å¾—ç›¸å°è·¯å¾‘ï¼Œä½¿ç”¨é è¨­ä½ç½®
            return Path(f"{self.file_path.stem}.csv")

    def _find_project_root(self) -> Path:
        """å°‹æ‰¾å°ˆæ¡ˆæ ¹ç›®éŒ„"""
        current = Path.cwd()
        
        # å‘ä¸Šå°‹æ‰¾åŒ…å« 01Data ç›®éŒ„çš„è³‡æ–™å¤¾
        while current != current.parent:
            if (current / "01Data").exists():
                return current
            current = current.parent
        
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œä½¿ç”¨ç•¶å‰å·¥ä½œç›®éŒ„
        return Path.cwd()

    def to_dataframe(self) -> pd.DataFrame:
        """å–å¾— pandas DataFrame æ ¼å¼çš„æ•¸æ“š"""
        if not self.data_records:
            self.read_data()
        
        data = []
        for r in self.data_records:
            row = [r['index']] + r['vm'].tolist() + r['vd'].tolist() + r['da'].tolist()
            data.append(row)
        
        columns = ['index'] + [f'vm_{i}' for i in range(6)] + [f'vd_{i}' for i in range(6)] + [f'da_{i}' for i in range(6)]
        return pd.DataFrame(data, columns=columns)


class BatchProcessor:
    """æ‰¹æ¬¡è™•ç†å™¨ - è™•ç†æ•´å€‹è³‡æ–™å¤¾"""
    
    def __init__(self, input_folder: str | Path, output_folder: Optional[str | Path] = None):
        self.input_folder = Path(input_folder)
        self.output_folder = Path(output_folder) if output_folder else None
        self.processed_files = []
        self.failed_files = []
        
        if not self.input_folder.exists():
            raise FileNotFoundError(f"è¼¸å…¥è³‡æ–™å¤¾ä¸å­˜åœ¨: {self.input_folder}")

    def find_dat_files(self, recursive: bool = True) -> List[Path]:
        """å°‹æ‰¾æ‰€æœ‰ .dat æª”æ¡ˆ"""
        if recursive:
            pattern = "**/*.dat"
        else:
            pattern = "*.dat"
        
        dat_files = list(self.input_folder.glob(pattern))
        print(f"æ‰¾åˆ° {len(dat_files)} å€‹ .dat æª”æ¡ˆ")
        return dat_files

    def process_folder(self, recursive: bool = True, skip_existing: bool = True) -> Dict:
        """æ‰¹æ¬¡è™•ç†æ•´å€‹è³‡æ–™å¤¾"""
        dat_files = self.find_dat_files(recursive)
        
        if not dat_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½• .dat æª”æ¡ˆ")
            return {"processed": 0, "failed": 0, "skipped": 0}
        
        processed_count = 0
        failed_count = 0
        skipped_count = 0
        
        print(f"\né–‹å§‹æ‰¹æ¬¡è™•ç† {len(dat_files)} å€‹æª”æ¡ˆ...")
        print("=" * 60)
        
        for i, file_path in enumerate(dat_files, 1):
            print(f"\n[{i}/{len(dat_files)}] è™•ç†æª”æ¡ˆ: {file_path.name}")
            
            try:
                # æ±ºå®šè¼¸å‡ºè·¯å¾‘
                output_path = self._get_output_path(file_path)
                
                # è™•ç†æª”æ¡ˆ
                reader = HSDataReader(file_path)
                
                # é©—è­‰æ ¼å¼
                header = reader.read_header()
                if not reader.validate_format():
                    print(f"âŒ æ ¼å¼é©—è­‰å¤±æ•—: {file_path}")
                    self.failed_files.append({"file": file_path, "error": "æ ¼å¼é©—è­‰å¤±æ•—"})
                    failed_count += 1
                    continue
                
                # è®€å–æ•¸æ“šä¸¦è½‰æ›
                data_records = reader.read_data()
                csv_path = reader.to_csv(str(output_path))
                
                self.processed_files.append({
                    "input": file_path,
                    "output": csv_path,
                    "records": len(data_records),
                    "size_mb": reader.get_info()["file_size_mb"]
                })
                
                processed_count += 1
                print(f"âœ… è™•ç†å®Œæˆ: {file_path.name}")
                
            except Exception as e:
                print(f"âŒ è™•ç†å¤±æ•—: {file_path.name} - {str(e)}")
                self.failed_files.append({"file": file_path, "error": str(e)})
                failed_count += 1
        
        # é¡¯ç¤ºç¸½çµ
        print("\n" + "=" * 60)
        print("æ‰¹æ¬¡è™•ç†å®Œæˆï¼")
        print(f"âœ… æˆåŠŸè™•ç†: {processed_count} å€‹æª”æ¡ˆ")
        print(f"âŒ è™•ç†å¤±æ•—: {failed_count} å€‹æª”æ¡ˆ")
        
        if self.failed_files:
            print("\nå¤±æ•—æª”æ¡ˆæ¸…å–®:")
            for failed in self.failed_files:
                print(f"  - {failed['file'].name}: {failed['error']}")
        
        return {
            "processed": processed_count,
            "failed": failed_count,
            "skipped": skipped_count,
            "processed_files": self.processed_files,
            "failed_files": self.failed_files
        }

    def _get_output_path(self, input_file: Path) -> Path:
        """å–å¾—è¼¸å‡ºæª”æ¡ˆè·¯å¾‘"""
        if self.output_folder:
            # ä½¿ç”¨æŒ‡å®šçš„è¼¸å‡ºè³‡æ–™å¤¾
            # ä¿æŒç›¸å°è·¯å¾‘çµæ§‹
            try:
                relative_path = input_file.relative_to(self.input_folder)
                output_path = self.output_folder / relative_path.with_suffix('.csv')
            except ValueError:
                # å¦‚æœç„¡æ³•å–å¾—ç›¸å°è·¯å¾‘ï¼Œç›´æ¥ä½¿ç”¨æª”å
                output_path = self.output_folder / input_file.with_suffix('.csv').name
        else:
            # ä½¿ç”¨è‡ªå‹•è·¯å¾‘ï¼ˆåŸæœ‰é‚è¼¯ï¼‰
            reader = HSDataReader(input_file)
            output_path = Path(reader._get_auto_csv_path())
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        output_path.parent.mkdir(parents=True, exist_ok=True)
        return output_path

def main():
    """ä¸»ç¨‹å¼ - æ‰¹æ¬¡è™•ç†ç‰ˆæœ¬"""
    
    # è¨­å®šè·¯å¾‘
    input_folder = "C:/Users/lu921/Desktop/git_repos/HSDATA/01Data/01Raw_dat"
    output_folder = "C:/Users/lu921/Desktop/git_repos/HSDATA/01Data/02Processed_csv"
    
    # æ–¹å¼1: ä½¿ç”¨æŒ‡å®šçš„è¼¸å‡ºè³‡æ–™å¤¾
    try:
        print("ğŸš€ é–‹å§‹æ‰¹æ¬¡è™•ç†...")
        processor = BatchProcessor(input_folder, output_folder)
        
        # è™•ç†æ•´å€‹è³‡æ–™å¤¾ (éè¿´æœå°‹å­è³‡æ–™å¤¾)
        results = processor.process_folder(
            recursive=True,      # éè¿´æœå°‹å­è³‡æ–™å¤¾
            skip_existing=True   # è·³éå·²å­˜åœ¨çš„æª”æ¡ˆ
        )
        
    except Exception as e:
        print(f"âŒ æ‰¹æ¬¡è™•ç†å¤±æ•—: {e}")
        return
    
    # æ–¹å¼2: ä½¿ç”¨è‡ªå‹•è·¯å¾‘ (è¨»è§£æ‰ï¼Œå¯ä¾éœ€æ±‚åˆ‡æ›)
    """
    try:
        print("ğŸš€ é–‹å§‹æ‰¹æ¬¡è™•ç† (è‡ªå‹•è·¯å¾‘)...")
        processor = BatchProcessor(input_folder)  # ä¸æŒ‡å®šè¼¸å‡ºè³‡æ–™å¤¾
        
        results = processor.process_folder(recursive=True, skip_existing=True)
        report_path = processor.generate_summary_report()
        
        print(f"\nğŸ‰ æ‰¹æ¬¡è™•ç†å…¨éƒ¨å®Œæˆï¼")
        print(f"ğŸ“Š è©³ç´°å ±å‘Š: {report_path}")
        
    except Exception as e:
        print(f"âŒ æ‰¹æ¬¡è™•ç†å¤±æ•—: {e}")
        return
    """


def single_file_example():
    """å–®æª”è™•ç†ç¯„ä¾‹ (ä¿ç•™åŸåŠŸèƒ½)"""
    file_path = "C:/Users/lu921/Desktop/git_repos/HSDATA/01Data/01Raw_dat/jump/500_jump_newB.dat"
    
    try:
        reader = HSDataReader(file_path)
        header = reader.read_header()
        
        if reader.validate_format():
            print("æª”æ¡ˆæ ¼å¼é©—è­‰é€šé")
            info = reader.get_info()
            print(f"æª”æ¡ˆå¤§å°: {info['file_size_mb']} MB")
            
            data_records = reader.read_data()
            df = reader.to_dataframe()
            csv_path = reader.to_csv()
            print(f"CSV æª”æ¡ˆå·²å„²å­˜è‡³: {csv_path}")
        
    except Exception as e:
        print(f"éŒ¯èª¤: {e}")


if __name__ == "__main__":
    main()  # åŸ·è¡Œæ‰¹æ¬¡è™•ç†
    # single_file_example()  # æˆ–åŸ·è¡Œå–®æª”è™•ç†ç¯„ä¾‹